{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train small YOLOv1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T17:00:36.190564Z",
     "start_time": "2018-09-16T17:00:36.177627Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0932dfed175c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0myolov1_small\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\git_projects\\YOLOv1\\pytorch_version\\yolov1_small.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVOC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataloader'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from torchsummary.torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yolov1_small\n",
    "\n",
    "from utilities import dataloader\n",
    "from utilities.utils import detection_collate_with_size\n",
    "from utilities.utils import save_checkpoint\n",
    "from utilities.utils import create_vis_plot\n",
    "from utilities.utils import update_vis_plot\n",
    "from utilities.augmentation import Augmenter\n",
    "from yolov1_small import detection_loss_4_small_yolo\n",
    "from dataloader import VOC\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Vidom on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:14.791215Z",
     "start_time": "2018-09-16T16:49:14.779248Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "viz = visdom.Visdom(use_incoming_socket=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:15.065511Z",
     "start_time": "2018-09-16T16:49:15.062489Z"
    }
   },
   "outputs": [],
   "source": [
    "vis_title = 'Yolo V1 Deepbaksu_vision (feat. martin, visionNoob) PyTorch on ' + 'VOC'\n",
    "vis_legend = ['Train Loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:15.440614Z",
     "start_time": "2018-09-16T16:49:15.409561Z"
    }
   },
   "outputs": [],
   "source": [
    "iter_plot = create_vis_plot(viz, 'Iteration', 'Total Loss', vis_title, vis_legend)\n",
    "coord1_plot = create_vis_plot(viz, 'Iteration', 'coord1', vis_title, vis_legend)\n",
    "size1_plot = create_vis_plot(viz, 'Iteration', 'size1', vis_title, vis_legend)\n",
    "noobjectness1_plot = create_vis_plot(viz, 'Iteration', 'noobjectness1', vis_title, vis_legend)\n",
    "objectness1_plot = create_vis_plot(viz, 'Iteration', 'objectness1', vis_title, vis_legend)\n",
    "obj_cls_plot = create_vis_plot(viz, 'Iteration', 'obj_cls', vis_title, vis_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:18.872796Z",
     "start_time": "2018-09-16T16:49:18.665916Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "USE_AUGMENTAION = False\n",
    "num_epochs = 16000\n",
    "num_classes = 1\n",
    "batch_size = 15\n",
    "learning_rate = 1e-3\n",
    "dropout_prop = 0.5\n",
    "\n",
    "DATASET_PATH_MARTIN = \"/media/keti-ai/AI_HARD3/DataSets/VOC_Pascal/VOC/VOCdevkit/VOC2012\"\n",
    "DATASET_PATH_JAEWON = \"H:\\VOC\\VOC12\\VOCdevkit_2\\VOC2012\"\n",
    "SMALL_DATASET_PATH = \"H:/person-300\"\n",
    "\n",
    "DATASET_PATH = SMALL_DATASET_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:00:39.026619Z",
     "start_time": "2018-09-16T16:00:38.811501Z"
    }
   },
   "source": [
    "# 2. Data augmentation setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:19.489153Z",
     "start_time": "2018-09-16T16:49:19.483170Z"
    }
   },
   "outputs": [],
   "source": [
    "if(USE_AUGMENTAION):\n",
    "    seq = iaa.SomeOf(2,[\n",
    "            iaa.Multiply((1.2, 1.5)), # change brightness, doesn't affect BBs\n",
    "            iaa.Affine(\n",
    "                translate_px={\"x\": 3, \"y\": 10},\n",
    "                scale=(0.9, 0.9)\n",
    "            ), # translate by 40/60px on x/y axis, and scale to 50-70%, affects BBs\n",
    "            iaa.AdditiveGaussianNoise(scale=0.1*255),\n",
    "            iaa.CoarseDropout(0.02, size_percent=0.15, per_channel=0.5),\n",
    "            iaa.Affine(rotate=45),\n",
    "            iaa.Sharpen(alpha=0.5)\n",
    "        ])\n",
    "else:\n",
    "     seq = iaa.Sequential([])\n",
    "\n",
    "composed = transforms.Compose([Augmenter(seq)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:20.758252Z",
     "start_time": "2018-09-16T16:49:20.639894Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = VOC(root = DATASET_PATH, transform=composed, cls_option = True, selective_cls=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:20.958716Z",
     "start_time": "2018-09-16T16:49:20.954727Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           collate_fn=detection_collate_with_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:29:00.203185Z",
     "start_time": "2018-09-16T16:29:00.200195Z"
    },
    "scrolled": true
   },
   "source": [
    "# 4. Sanity Check for dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:24.051315Z",
     "start_time": "2018-09-16T16:49:21.817198Z"
    }
   },
   "outputs": [],
   "source": [
    "images, labels, size = iter(train_loader).next()\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:49:33.632454Z",
     "start_time": "2018-09-16T16:49:33.502553Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(images[0],(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load YOLOv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:33:30.584137Z",
     "start_time": "2018-09-16T16:33:28.842657Z"
    }
   },
   "outputs": [],
   "source": [
    "net = yolov1_small.SmallYOLOv1()\n",
    "# visualize_weights_distribution(net)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:33:38.839918Z",
     "start_time": "2018-09-16T16:33:36.820321Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = yolov1_small.SmallYOLOv1().to(device)\n",
    "#model = torch.nn.DataParallel(net, device_ids=[0]).cuda()\n",
    "\n",
    "#summary(model, (3, 448,448))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-16T16:32:30.620Z"
    }
   },
   "source": [
    "# 6. Sanity Check for output dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:33:46.078556Z",
     "start_time": "2018-09-16T16:33:45.181956Z"
    }
   },
   "outputs": [],
   "source": [
    "#for just a image\n",
    "num = 2\n",
    "test_image = images[num]\n",
    "outputs = model(torch.cuda.FloatTensor(np.expand_dims(test_image,axis=0)))\n",
    "print(outputs.shape)\n",
    "\n",
    "#for images (batch size)\n",
    "outputs = model(torch.cuda.FloatTensor(images))\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T16:34:24.008132Z",
     "start_time": "2018-09-16T16:34:24.004117Z"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-16T16:02:22.065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    if (epoch == 200) or (epoch == 400) or (epoch == 600) or (epoch == 20000) or (epoch == 30000):\n",
    "        scheduler.step()\n",
    "\n",
    "    for i, (images, labels, size) in enumerate(train_loader):\n",
    "\n",
    "    \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calc Loss\n",
    "        loss, \\\n",
    "        obj_coord1_loss, \\\n",
    "        obj_size1_loss, \\\n",
    "        obj_class_loss, \\\n",
    "        noobjness1_loss, \\\n",
    "        objness1_loss = detection_loss_4_small_yolo(outputs, labels)\n",
    "        #objness2_loss = yolov1.detection_loss(outputs, labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            \n",
    "            print('Epoch ,[{}/{}] ,Step ,[{}/{}] ,lr ,{} ,total_loss ,{:.4f} ,coord1 ,{} ,size1 ,{} ,noobj_clss ,{} ,objness1 ,{} ,'\n",
    "                  .format(epoch + 1,\n",
    "                          num_epochs,\n",
    "                          i + 1,\n",
    "                          total_step,\n",
    "                          [param_group['lr'] for param_group in optimizer.param_groups],\n",
    "                          loss.item(),\n",
    "                          obj_coord1_loss,\n",
    "                          obj_size1_loss,\n",
    "                          obj_class_loss,\n",
    "                          noobjness1_loss,\n",
    "                          objness1_loss\n",
    "                          ))\n",
    "            \n",
    "\n",
    "            update_vis_plot(viz, (epoch+1)*batch_size +(i + 1), loss.item(), iter_plot, None, 'append')\n",
    "            update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), obj_coord1_loss, coord1_plot, None, 'append')\n",
    "            update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), obj_size1_loss, size1_plot, None, 'append')\n",
    "            update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), obj_class_loss, obj_cls_plot, None, 'append')\n",
    "            update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), noobjness1_loss, noobjectness1_plot, None, 'append')\n",
    "            update_vis_plot(viz, (epoch + 1) * batch_size + (i + 1), objness1_loss, objectness1_plot, None, 'append')\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    if (epoch % 300) == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': \"YOLOv1\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, False, filename='checkpoints/checkpoint_{}.pth.tar'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST \n",
    "Todo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           collate_fn=detection_collate)\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(test_image,axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
